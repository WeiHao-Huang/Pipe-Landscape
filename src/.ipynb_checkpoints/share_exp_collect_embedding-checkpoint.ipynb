{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8964289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import schedulefree\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import config\n",
    "from data.utils import DataReader, get_dataset\n",
    "import distributed\n",
    "from models.utils import get_model\n",
    "from optim.base import train\n",
    "from optim.utils import cos_inf_schedule, wsd_schedule, get_batch\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]\n",
    "    \n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(allow_abbrev=False)\n",
    "    parser.add_argument(\n",
    "        \"--config_format\", default=\"base\", choices=config.registered_formats()\n",
    "    )\n",
    "    args, rem_args = parser.parse_known_args()\n",
    "    args.n_layer=12\n",
    "    args.n_head=12\n",
    "    args.n_embd=768\n",
    "    args.datasets_dir = \"/chenyupeng/data_files/llm_datasets\"\n",
    "    return config.parse_args_with_format(\n",
    "        format=args.config_format, base_parser=parser, args=rem_args, namespace=args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1400c4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8229de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196cc9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/chenyupeng/data_files/llm_datasets/slimpajama6B/\n",
      "Num training tokens: 5827933038\n",
      "Num validation tokens: 9479563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data_readers(args, verbose=True):\n",
    "    data_srcs = get_dataset(args)\n",
    "    train_reader = DataReader(\n",
    "        data_src=data_srcs[\"train\"],\n",
    "        batch_size=args.batch_size,\n",
    "        sequence_length=args.sequence_length,\n",
    "        seed=args.data_seed,\n",
    "        with_replacement=False,\n",
    "        auto_shard=True,\n",
    "        keep_in_ram=args.data_in_ram,\n",
    "    )\n",
    "    val_reader = DataReader(\n",
    "        data_src=data_srcs[\"val\"],\n",
    "        batch_size=args.batch_size,\n",
    "        sequence_length=args.sequence_length,\n",
    "        seed=args.data_seed,\n",
    "        with_replacement=False,\n",
    "        auto_shard=False,  # NOTE Identical Per Rank\n",
    "        keep_in_ram=args.data_in_ram,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Num training tokens: {train_reader.num_tokens}\")\n",
    "        print(f\"Num validation tokens: {val_reader.num_tokens}\")\n",
    "\n",
    "    return {\n",
    "        \"train\": train_reader,\n",
    "        \"val\": val_reader,\n",
    "    }\n",
    "data = get_data_readers(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64e2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ecddca-feb9-431c-95e0-f2a21a52a471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275a9e7-eda4-45a7-b8f2-0136c7ac23a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4863a-fafd-4b7a-b3a7-59137699464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4e7e02-0025-4648-b853-107723b93715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import torch\n",
    "\n",
    "def enable_collect_embedding(layer, layer_id):\n",
    "    \"\"\"\n",
    "    replace the forward function of LlamaDecoderLayer with a custom forward function `llama_custom_decoderlayer_forward`\n",
    "    \"\"\"\n",
    "    layer.layer_id = layer_id\n",
    "    layer.forward = types.MethodType(\n",
    "        block_forward, layer\n",
    "    )\n",
    "\n",
    "\n",
    "def block_forward(self, x, freqs_cis):\n",
    "    x = x + self.attn(self.ln_1(x), freqs_cis)\n",
    "    temp = self.ln_2(x)\n",
    "    self.input = temp.detach()\n",
    "    x_ = self.mlp(temp)\n",
    "    self.output = x_.detach()\n",
    "    x = x + x_\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723fd4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def load_ck_state(model, step):\n",
    "    model_new = copy.deepcopy(model)\n",
    "    current_ckpt = torch.load(f\"/chenyupeng/old_files/yupeng_gpt/WSD/river_valley_project/llama_100m/slimpajama_llama_nlayers12_nhead12_lr0.001_sched_wsd_warmup300_decay_linear_0.1_iter25000_bs50x2_ws2_seed0_data_seed1337/ckpts/{step}/main.pt\",map_location=torch.device('cpu'))\n",
    "    new_state_dict = {}\n",
    "    for key, value in current_ckpt[\"model\"].items():\n",
    "        new_key = key.replace('_orig_mod.', '')\n",
    "        new_key = new_key.replace('module.', '')# 移除前缀\n",
    "        new_state_dict[new_key] = value\n",
    "    model_new.load_state_dict(new_state_dict)\n",
    "    return model_new \n",
    "    \n",
    "model = load_ck_state(model, 25000)\n",
    "#current_ckpt = torch.load(f\"/mntcephfs/lab_data/chenyupeng/senmiao_jaggi_exp_results/slimpajama_llama_nlayers8_nhead6_lr0.002_sched_wsd_warmup1500_decay_linear_0.1_iter15000_bs50x4_ws1_seed0_data_seed1337/ckpts/12000/main.pt\",map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a8d587-225d-4b73-b497-14ad3e91073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc04ec0-97fe-4aca-80e8-1127fedbcf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/chenyupeng/data_files/llm_datasets/slimpajama6B/\n",
      "Num training tokens: 5827933038\n",
      "Num validation tokens: 9479563\n"
     ]
    }
   ],
   "source": [
    "data_reader = get_data_readers(args)[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9bfecf-43b7-4d04-91a4-eb1d16681477",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    enable_collect_embedding(model.transformer.h[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ed6ba4-60d9-4296-9e35-6ad83a5ed98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding = torch.zeros(1,50,512,768,12)\n",
    "output_embedding = torch.zeros(1,50,512,768,12)\n",
    "with torch.no_grad():\n",
    "    for i in range(1):\n",
    "        x, y = get_batch(data_reader, device=\"cuda\")\n",
    "        \n",
    "        outputs = model(x, targets=y, get_logits=True)\n",
    "    \n",
    "        for z in range(12):\n",
    "            input_embedding[i,:,:,:,z] = model.transformer.h[z].input.cpu()\n",
    "            output_embedding[i,:,:,:,z] = model.transformer.h[z].output.cpu()\n",
    "            model.transformer.h[z].input = None\n",
    "            model.transformer.h[z].output = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d54caa-3c4a-4839-b777-17b7e13b7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_embedding, \"/chenyupeng/share_experts/gpt2_100m_embedding_data/input_embedding.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6222f51-6eb1-4166-ac75-46a53aff5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output_embedding, \"/chenyupeng/share_experts/gpt2_100m_embedding_data/output_embedding.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec28862-c4cf-4589-b7d3-18ce350ec633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x LlamaBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): LlamaAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): LlamaMLP(\n",
       "          (w1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "          (w2): Linear(in_features=768, out_features=2048, bias=False)\n",
       "          (c_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e418f186-505b-4a8c-9c8d-a15f3d24e566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662109375"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20*50*512*768/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eda85c8b-9655-4880-990c-9a5003d6c324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 512, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[11].input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5b26b02-0314-4a48-91db-98267903833c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9479050"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711a825e-06f2-4fc9-8d5c-1ce64ae2bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x LlamaBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): LlamaAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): LlamaMLP(\n",
       "          (w1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "          (w2): Linear(in_features=768, out_features=2048, bias=False)\n",
       "          (c_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
