{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d07ad0-84b7-4d18-b644-2e546dba0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import math\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a4364a-3ec0-435a-a8d6-1af64b092900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import schedulefree\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import config\n",
    "from data.utils import DataReader, get_dataset\n",
    "import distributed\n",
    "from models.utils import get_model\n",
    "from optim.base import train\n",
    "from optim.utils import cos_inf_schedule, wsd_schedule, get_batch\n",
    "\n",
    "import sys\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "   sys.argv = sys.argv[:1]\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(allow_abbrev=False)\n",
    "    parser.add_argument(\n",
    "        \"--config_format\", default=\"base\", choices=config.registered_formats()\n",
    "    )\n",
    "    args, rem_args = parser.parse_known_args()\n",
    "    args.n_layer=3\n",
    "    args.n_head=6\n",
    "    args.n_embd=60\n",
    "    args.multiple_of=1\n",
    "    args.batch_size=1\n",
    "    args.dtype = \"float32\"\n",
    "    args.datasets_dir = \"/chenyupeng/data_files/llm_datasets\"\n",
    "    return config.parse_args_with_format(\n",
    "        format=args.config_format, base_parser=parser, args=rem_args, namespace=args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc28eac-2cfc-437c-8a2e-e9b078dca6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c1aea07-22bf-4a1e-aaaa-00a10acdd1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/chenyupeng/data_files/llm_datasets/slimpajama6B/\n",
      "Num training tokens: 5827933038\n",
      "Num validation tokens: 9479563\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "\n",
    "import copy\n",
    "def get_data_readers(args, verbose=True):\n",
    "    data_srcs = get_dataset(args)\n",
    "    train_reader = DataReader(\n",
    "        data_src=data_srcs[\"train\"],\n",
    "        batch_size=args.batch_size,\n",
    "        sequence_length=args.sequence_length,\n",
    "        seed=args.data_seed,\n",
    "        with_replacement=False,\n",
    "        auto_shard=True,\n",
    "        keep_in_ram=args.data_in_ram,\n",
    "    )\n",
    "    val_reader = DataReader(\n",
    "        data_src=data_srcs[\"val\"],\n",
    "        batch_size=args.batch_size,\n",
    "        sequence_length=args.sequence_length,\n",
    "        seed=args.data_seed,\n",
    "        with_replacement=False,\n",
    "        auto_shard=False,  # NOTE Identical Per Rank\n",
    "        keep_in_ram=args.data_in_ram,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Num training tokens: {train_reader.num_tokens}\")\n",
    "        print(f\"Num validation tokens: {val_reader.num_tokens}\")\n",
    "\n",
    "    return {\n",
    "        \"train\": train_reader,\n",
    "        \"val\": val_reader,\n",
    "    }\n",
    "data = get_data_readers(args)\n",
    "\n",
    "\n",
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a571b44d-9cd2-4ff1-8054-09bd56fc2eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 100)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x LlamaBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): LlamaAttention(\n",
       "          (c_attn): Linear(in_features=100, out_features=300, bias=False)\n",
       "          (c_proj): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): LlamaMLP(\n",
       "          (w1): Linear(in_features=100, out_features=266, bias=False)\n",
       "          (w2): Linear(in_features=100, out_features=266, bias=False)\n",
       "          (c_proj): Linear(in_features=266, out_features=100, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=100, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad66ddd-bd6c-41af-b53a-8a0ce01fb949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/chenyupeng/data_files/llm_datasets/slimpajama6B/\n",
      "Num training tokens: 5827933038\n",
      "Num validation tokens: 9479563\n"
     ]
    }
   ],
   "source": [
    "val_batches = []\n",
    "data_reader = get_data_readers(args)[\"val\"]\n",
    "for _ in range(10):\n",
    "    z_x, z_y = get_batch(data_reader, device=\"cuda\")\n",
    "    val_batches.append((z_x, z_y))\n",
    "eval_batches = val_batches[0]  # 使用前10个batch评估\n",
    "\n",
    "#set_seed(100)\n",
    "#for i in range(eval_batches[0].shape[1]):\n",
    "#    eval_batches[0][0,i].data.copy_(random.randint(0, 19))\n",
    "#    if i>=1:\n",
    "#        eval_batches[1][0,i] = eval_batches[0][0,i-1]\n",
    "#eval_batches[1][0,-1] = random.randint(0, 19)\n",
    "def compute_grad(model,eval_batches):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    # 清空梯度\n",
    "    for p in model.parameters():\n",
    "        p.grad = None\n",
    "    \n",
    "    # 梯度累积\n",
    "    #for x, y in eval_batches:\n",
    "    x = eval_batches[0]\n",
    "    y = eval_batches[1]\n",
    "    outputs = model(x, targets=y, get_logits=True)\n",
    "    batch_loss = outputs[\"loss\"]*1e4\n",
    "    \n",
    "    # 通过缩放损失实现梯度累积，相当于平均梯度\n",
    "    batch_loss.backward()  # 梯度会累积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633cdb92-004a-4553-9c44-582fcd1f7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def get_hessian(model,eval_batches,a,r):\n",
    "    compute_grad(model,eval_batches)\n",
    "    grad_original = model.transformer.h[-1].mlp.c_proj.weight.grad.detach().clone()\n",
    "    original_weight = model.transformer.h[-1].mlp.c_proj.weight.data.detach().clone()\n",
    "    set_seed(42)\n",
    "    random_phi = torch.randn_like(model.transformer.h[-1].mlp.c_proj.weight)\n",
    "    for i in range(2000):\n",
    "        #random_phi = random_phi/torch.norm(random_phi)\n",
    "        model.transformer.h[-1].mlp.c_proj.weight.data.add_((random_phi/torch.norm(random_phi))*a)\n",
    "        compute_grad(model,eval_batches)\n",
    "        grad_after_pertu = model.transformer.h[-1].mlp.c_proj.weight.grad.data.detach().clone()\n",
    "        random_phi = (1-r)*random_phi + (r/a)*(grad_after_pertu-grad_original)\n",
    "        model.transformer.h[-1].mlp.c_proj.weight.data.copy_(original_weight)\n",
    "        weight_norm_of_random = random_phi.norm()\n",
    "        simi = F.cosine_similarity(grad_original.reshape(-1), (random_phi/torch.norm(random_phi)).reshape(-1), dim=0)\n",
    "        print(f\"{i}-th iteration, grad norm of phi: {weight_norm_of_random}, simi : {simi}\")\n",
    "\n",
    "    random_phi = random_phi/random_phi.norm()\n",
    "    #cosine_simi = F.cosine_similarity(grad_original.reshape(-1), random_phi.reshape(-1), dim=0)\n",
    "    return random_phi,simi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d144f662-40f8-4d35-9235-9dfb486a10e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iteration, grad norm of phi: 175.6248016357422, simi : 0.003978067077696323\n",
      "1-th iteration, grad norm of phi: 158.19244384765625, simi : 0.003338780254125595\n",
      "2-th iteration, grad norm of phi: 142.643310546875, simi : 0.0030107153579592705\n",
      "3-th iteration, grad norm of phi: 128.86228942871094, simi : 0.0028320476412773132\n",
      "4-th iteration, grad norm of phi: 116.85551452636719, simi : 0.002635692246258259\n",
      "5-th iteration, grad norm of phi: 106.9105453491211, simi : 0.0016653588972985744\n",
      "6-th iteration, grad norm of phi: 100.17897033691406, simi : -0.0013499893248081207\n",
      "7-th iteration, grad norm of phi: 100.11438751220703, simi : -0.00937785767018795\n",
      "8-th iteration, grad norm of phi: 113.89456176757812, simi : -0.023671213537454605\n",
      "9-th iteration, grad norm of phi: 146.63888549804688, simi : -0.039449892938137054\n",
      "10-th iteration, grad norm of phi: 192.316650390625, simi : -0.05132779851555824\n",
      "11-th iteration, grad norm of phi: 241.82017517089844, simi : -0.05948349088430405\n",
      "12-th iteration, grad norm of phi: 290.3760070800781, simi : -0.06539095193147659\n",
      "13-th iteration, grad norm of phi: 336.12841796875, simi : -0.06993171572685242\n",
      "14-th iteration, grad norm of phi: 378.4920349121094, simi : -0.07359541952610016\n",
      "15-th iteration, grad norm of phi: 417.3447265625, simi : -0.07668979465961456\n",
      "16-th iteration, grad norm of phi: 452.8264465332031, simi : -0.0793505534529686\n",
      "17-th iteration, grad norm of phi: 485.1125793457031, simi : -0.08168773353099823\n",
      "18-th iteration, grad norm of phi: 514.4434814453125, simi : -0.08380267024040222\n",
      "19-th iteration, grad norm of phi: 541.0542602539062, simi : -0.0857076346874237\n",
      "20-th iteration, grad norm of phi: 565.1646118164062, simi : -0.0874616801738739\n",
      "21-th iteration, grad norm of phi: 587.0154418945312, simi : -0.08908042311668396\n",
      "22-th iteration, grad norm of phi: 606.7806396484375, simi : -0.09057879447937012\n",
      "23-th iteration, grad norm of phi: 624.6901245117188, simi : -0.09197649359703064\n",
      "24-th iteration, grad norm of phi: 640.8834228515625, simi : -0.09328722208738327\n",
      "25-th iteration, grad norm of phi: 655.5323486328125, simi : -0.09451492875814438\n",
      "26-th iteration, grad norm of phi: 668.7763061523438, simi : -0.09569277614355087\n",
      "27-th iteration, grad norm of phi: 680.7561645507812, simi : -0.0968131572008133\n",
      "28-th iteration, grad norm of phi: 691.5946044921875, simi : -0.09788854420185089\n",
      "29-th iteration, grad norm of phi: 701.4049072265625, simi : -0.09888867288827896\n",
      "30-th iteration, grad norm of phi: 710.2813110351562, simi : -0.0998481959104538\n",
      "31-th iteration, grad norm of phi: 718.298095703125, simi : -0.10077354311943054\n",
      "32-th iteration, grad norm of phi: 725.557373046875, simi : -0.10167054831981659\n",
      "33-th iteration, grad norm of phi: 732.1309204101562, simi : -0.10251829028129578\n",
      "34-th iteration, grad norm of phi: 738.0703735351562, simi : -0.10333926230669022\n",
      "35-th iteration, grad norm of phi: 743.4356079101562, simi : -0.1041150763630867\n",
      "36-th iteration, grad norm of phi: 748.301025390625, simi : -0.10486677289009094\n",
      "37-th iteration, grad norm of phi: 752.7158203125, simi : -0.10558870434761047\n",
      "38-th iteration, grad norm of phi: 756.7178955078125, simi : -0.10628590732812881\n",
      "39-th iteration, grad norm of phi: 760.33740234375, simi : -0.10695673525333405\n",
      "40-th iteration, grad norm of phi: 763.6127319335938, simi : -0.10760022699832916\n",
      "41-th iteration, grad norm of phi: 766.57763671875, simi : -0.10822226107120514\n",
      "42-th iteration, grad norm of phi: 769.2709350585938, simi : -0.10882948338985443\n",
      "43-th iteration, grad norm of phi: 771.7158813476562, simi : -0.10940666496753693\n",
      "44-th iteration, grad norm of phi: 773.9335327148438, simi : -0.10996311902999878\n",
      "45-th iteration, grad norm of phi: 775.9395751953125, simi : -0.11050398647785187\n",
      "46-th iteration, grad norm of phi: 777.7608642578125, simi : -0.1110229641199112\n",
      "47-th iteration, grad norm of phi: 779.4136352539062, simi : -0.11152207851409912\n",
      "48-th iteration, grad norm of phi: 780.9136352539062, simi : -0.1120070144534111\n",
      "49-th iteration, grad norm of phi: 782.2799682617188, simi : -0.11248041689395905\n",
      "50-th iteration, grad norm of phi: 783.52490234375, simi : -0.11294104903936386\n",
      "51-th iteration, grad norm of phi: 784.65087890625, simi : -0.11338366568088531\n",
      "52-th iteration, grad norm of phi: 785.6703491210938, simi : -0.11380834877490997\n",
      "53-th iteration, grad norm of phi: 786.6006469726562, simi : -0.11421419680118561\n",
      "54-th iteration, grad norm of phi: 787.4526977539062, simi : -0.11460418999195099\n",
      "55-th iteration, grad norm of phi: 788.2247924804688, simi : -0.11497213691473007\n",
      "56-th iteration, grad norm of phi: 788.930908203125, simi : -0.11533091962337494\n",
      "57-th iteration, grad norm of phi: 789.581298828125, simi : -0.11568700522184372\n",
      "58-th iteration, grad norm of phi: 790.1786499023438, simi : -0.11602914333343506\n",
      "59-th iteration, grad norm of phi: 790.724853515625, simi : -0.11635953187942505\n",
      "60-th iteration, grad norm of phi: 791.2254638671875, simi : -0.11668529361486435\n",
      "61-th iteration, grad norm of phi: 791.6844482421875, simi : -0.11698631197214127\n",
      "62-th iteration, grad norm of phi: 792.1062622070312, simi : -0.11728066205978394\n",
      "63-th iteration, grad norm of phi: 792.489501953125, simi : -0.11756370961666107\n",
      "64-th iteration, grad norm of phi: 792.8382568359375, simi : -0.11783769726753235\n",
      "65-th iteration, grad norm of phi: 793.1535034179688, simi : -0.11810239404439926\n",
      "66-th iteration, grad norm of phi: 793.4486694335938, simi : -0.1183486357331276\n",
      "67-th iteration, grad norm of phi: 793.7246704101562, simi : -0.1185888722538948\n",
      "68-th iteration, grad norm of phi: 793.9749755859375, simi : -0.11882251501083374\n",
      "69-th iteration, grad norm of phi: 794.2061157226562, simi : -0.11904400587081909\n",
      "70-th iteration, grad norm of phi: 794.423583984375, simi : -0.11926333606243134\n",
      "71-th iteration, grad norm of phi: 794.6256713867188, simi : -0.1194738894701004\n",
      "72-th iteration, grad norm of phi: 794.8082885742188, simi : -0.11967635899782181\n",
      "73-th iteration, grad norm of phi: 794.9730834960938, simi : -0.11986567080020905\n",
      "74-th iteration, grad norm of phi: 795.1364135742188, simi : -0.12005244940519333\n",
      "75-th iteration, grad norm of phi: 795.2921142578125, simi : -0.12022249400615692\n",
      "76-th iteration, grad norm of phi: 795.4396362304688, simi : -0.12038113176822662\n",
      "77-th iteration, grad norm of phi: 795.5737915039062, simi : -0.1205345019698143\n",
      "78-th iteration, grad norm of phi: 795.6961669921875, simi : -0.12068179994821548\n",
      "79-th iteration, grad norm of phi: 795.8120727539062, simi : -0.12082387506961823\n",
      "80-th iteration, grad norm of phi: 795.91748046875, simi : -0.12095387279987335\n",
      "81-th iteration, grad norm of phi: 796.0162353515625, simi : -0.12107664346694946\n",
      "82-th iteration, grad norm of phi: 796.1116943359375, simi : -0.12119212746620178\n",
      "83-th iteration, grad norm of phi: 796.2030639648438, simi : -0.12130516767501831\n",
      "84-th iteration, grad norm of phi: 796.287109375, simi : -0.12141332030296326\n",
      "85-th iteration, grad norm of phi: 796.3646850585938, simi : -0.12152118980884552\n",
      "86-th iteration, grad norm of phi: 796.4382934570312, simi : -0.12162263691425323\n",
      "87-th iteration, grad norm of phi: 796.513427734375, simi : -0.12171962857246399\n",
      "88-th iteration, grad norm of phi: 796.5806884765625, simi : -0.12180408835411072\n",
      "89-th iteration, grad norm of phi: 796.6451416015625, simi : -0.12188366055488586\n",
      "90-th iteration, grad norm of phi: 796.7034912109375, simi : -0.12195557355880737\n",
      "91-th iteration, grad norm of phi: 796.754638671875, simi : -0.12202362716197968\n",
      "92-th iteration, grad norm of phi: 796.801513671875, simi : -0.12208697199821472\n",
      "93-th iteration, grad norm of phi: 796.843017578125, simi : -0.12215184420347214\n",
      "94-th iteration, grad norm of phi: 796.88623046875, simi : -0.12220817059278488\n",
      "95-th iteration, grad norm of phi: 796.9292602539062, simi : -0.12225483357906342\n",
      "96-th iteration, grad norm of phi: 796.9718627929688, simi : -0.12229537963867188\n",
      "97-th iteration, grad norm of phi: 797.008544921875, simi : -0.12233978509902954\n",
      "98-th iteration, grad norm of phi: 797.0464477539062, simi : -0.12237124145030975\n",
      "99-th iteration, grad norm of phi: 797.08447265625, simi : -0.12240176647901535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model.eval()\n",
    "phi,simi = get_hessian(model,eval_batches,0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73115b45-9ee2-4c6c-9efd-f3fa02646c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 53])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b91f8282-5ba3-456b-bcf8-a701c22b0d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 53])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[-1].mlp.c_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8929d93-9b8b-4d02-992d-469fffae3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0006, -0.0034,  0.0140,  ...,  0.0186, -0.0074,  0.0134],\n",
       "        [-0.0225,  0.0089, -0.0028,  ..., -0.0131,  0.0037, -0.0078],\n",
       "        [ 0.0032,  0.0076, -0.0307,  ...,  0.0057,  0.0003, -0.0009],\n",
       "        ...,\n",
       "        [ 0.0147, -0.0062, -0.0018,  ...,  0.0036,  0.0254, -0.0131],\n",
       "        [-0.0121,  0.0002,  0.0063,  ...,  0.0144,  0.0037,  0.0080],\n",
       "        [-0.0209,  0.0114,  0.0203,  ..., -0.0019,  0.0037, -0.0361]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[-1].mlp.c_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e762239-714f-4cdc-9c63-7ecc1b9f3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb3031a-262b-4418-a95c-a94bc5057f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model.zero_grad(set_to_none = True)\n",
    "model.eval()\n",
    "x = eval_batches[0]\n",
    "y = eval_batches[1]\n",
    "outputs = model(x, targets=y, get_logits=True)\n",
    "batch_loss = outputs[\"loss\"]*1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f770742-b47a-4690-a97c-61b7a7b84328",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [p for n,p in model.named_parameters() if \"mlp.c_proj\" in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bc097d6-f71d-4696-a2f4-3ae00210b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_grads = torch.autograd.grad(batch_loss, parameters, create_graph=True,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f12b7d6-299e-470f-9174-043f43468dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian = torch.zeros((parameters[0].numel(), parameters[0].numel()), device=parameters[0].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "011c7e5d-b7da-41fb-9d46-0b0915a174ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_order_grads = first_order_grads[0].view(-1)\n",
    "#hessian_vector = torch.autograd.grad(first_order_grads, parameters, retain_graph=True)\n",
    "\n",
    "\n",
    "for i in range(parameters[0].numel()):\n",
    "    grad2 = torch.autograd.grad(first_order_grads[0].flatten()[i].double(), parameters, retain_graph=True)[0]\n",
    "            \n",
    "    if grad2 is not None:\n",
    "        hessian[i, :] = grad2.flatten()\n",
    "    else:\n",
    "        print(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d12c90b1-7beb-4fa3-b692-9c03b344301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad(set_to_none = True)\n",
    "model = model.cuda()\n",
    "x = eval_batches[0]\n",
    "y = eval_batches[1]\n",
    "model.eval()\n",
    "import time\n",
    "def hessian_calculation(g_tensor, params):\n",
    "    g_tensor = g_tensor.cuda()\n",
    "    total_params = g_tensor.size(0)\n",
    "    hessian_list = []\n",
    "    t_d = time.time()\n",
    "    for d in range(total_params):\n",
    "        unit_vector = torch.zeros_like(g_tensor)\n",
    "        unit_vector[d] = 1\n",
    "        l = torch.sum(g_tensor * unit_vector)\n",
    "        grad_2 = torch.autograd.grad(l, params[0], create_graph=True)\n",
    "        #l.backward(retain_graph= True)\n",
    "        hessian_row = []\n",
    "        #print('name',name, param.grad)\n",
    "        hessian_row.append(grad_2[0].double().data.clone())\n",
    "        \n",
    "        model.zero_grad(set_to_none = True)\n",
    "        hessian_row = [g.flatten() for g in hessian_row] \n",
    "        hessian_row = [g.cpu() for g in hessian_row]\n",
    "        hessian_row = torch.cat(hessian_row)\n",
    "        #print('hessian_row', hessian_row)   \n",
    "        hessian_list.append(hessian_row)\n",
    "        # if d % 1000 == 0:\n",
    "        #     print(f'Computing hessian: current batch = {batch_idx}/{self.num_batches}, current row of a hessian: {d}/{total_params}, total time = {time.time()- t_d} ')\n",
    "    hessian = torch.stack(hessian_list, dim = 1)\n",
    "    #print('hessian', hessian)   \n",
    "    return hessian\n",
    "full_hessian = 0\n",
    "outputs = model(x, targets=y, get_logits=True)\n",
    "batch_loss = outputs[\"loss\"]*1e4\n",
    "#batch_loss.backward(create_graph= True)\n",
    "#g_list = []\n",
    "#count = 0\n",
    "parameters = [p for n,p in model.named_parameters() if \"mlp.c_proj\" in n]\n",
    "#if parameters[0].requires_grad:\n",
    "#    count += parameters[0].numel()\n",
    "#    #print('g shape', param.grad , param.grad.shape)\n",
    "#    g_list.append(torch.flatten(parameters[0].grad.double()))\n",
    "#    #print('name',name, g_list[-1].size())\n",
    "#g_tensor = torch.cat(g_list, dim = 0)\n",
    "grad_para = torch.autograd.grad(batch_loss, parameters, create_graph=True,retain_graph=True)\n",
    "g_tensor = torch.flatten(grad_para[0].double())\n",
    "#print('g_tensor',g_tensor)\n",
    "model.zero_grad(set_to_none = True)\n",
    "H = hessian_calculation(g_tensor,parameters)\n",
    "full_hessian += H\n",
    "full_hessian = torch.nan_to_num(full_hessian, nan = 0, posinf = 0, neginf = 0 )  # change nan, postive inf , negative inf, to 0\n",
    "t_svd = time.time()\n",
    "#print('doing EVD')\n",
    "# _, eigenvalues, _ = torch.linalg.svd(full_hessian)  # ascending\n",
    "#eigenvalues, _  = torch.eig(full_hessian)\n",
    "full_hessian = full_hessian.numpy().astype(np.float64)\n",
    "full_hessian = (full_hessian + full_hessian.T)/2 # make symetric, to \n",
    "\n",
    "\n",
    "\n",
    "#avoid numerical issue\n",
    "#full_hessian = full_hessian.cuda()\n",
    "#eigenvalues, _  = torch.linalg.eig(full_hessian)\n",
    "# eigenvalues, _  = np.linalg.eigh(full_hessian)\n",
    "# #_, eigenvalues, _ = np.linalg.svd(full_hessian) \n",
    "# eigenvalues = [eigen.item().real for eigen in eigenvalues]\n",
    "# file_name = self.file_dir + 'eigenvalues.txt'\n",
    "# with open(file_name, \"w\") as file:\n",
    "#     for item in eigenvalues:\n",
    "#         file.write(str(item)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb860dfa-62c9-487e-82fd-71f5f13537bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "409600 / 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa89625-7322-48f1-a2c1-d5e607cd67c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*512*4*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdf79ae8-6516-4118-b5db-5e4c76969c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hessian = torch.tensor(full_hessian).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cb545a8-391d-46ce-82ea-6208b02104ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9600, 9600])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hessian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ffc749-31c2-4378-bd61-a79a72a063dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e10/1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69eb8d89-ca5e-4519-bf91-40a8387308e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6993d2f1-550e-4787-ad86-c11ab5d1d553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 5120)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hessian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4214ac-eac2-4903-8235-660045bf3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v,d = torch.linalg.svd(torch.tensor(full_hessian).cuda((.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28db5685-094e-46c3-aceb-f0349909c061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1715e+01, 9.1922e+00, 8.8347e+00,  ..., 6.7539e-07, 5.1691e-07,\n",
       "        9.5747e-08], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c103f1c6-ab65-4f01-add1-58148484a909",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "F.cosine_similarity(phi.reshape(-1), d[0,:],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d568f79f-eb0a-4b93-8424-d2eb79783612",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'double'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u,v,d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'double'"
     ]
    }
   ],
   "source": [
    "u,v,d = torch.linalg.svd(hessian.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0644691a-995c-4c8f-9f67-80403e98d6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.4398e+00, 7.2601e+00, 6.8293e+00,  ..., 4.8793e-07, 2.4023e-07,\n",
       "        2.1420e-07], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea565877-460e-4da6-9eaf-4d470b1e7a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8252e-07,  3.4268e-06,  1.2450e-04,  ...,  5.5907e-05,\n",
       "        -1.9799e-05,  4.9336e-05], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(hessian, phi.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e81f8e5d-8fff-4b73-952d-98b01a504acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.2583, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(hessian, phi.reshape(-1))).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de2b1aa-e35b-41ad-bccb-6c53941aaa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2283, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(phi.reshape(-1)*7.122495174407959 - torch.matmul(hessian, phi.reshape(-1))).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c053535-3a2f-43a5-ae46-3e23e5c0e35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(phi.reshape(-1), d[0,:],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e6f350-3d35-46ca-8df1-400694f26d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2368e-07,  5.7056e-06,  1.2471e-05,  ...,  3.9668e-07,\n",
       "         2.2853e-07, -1.4662e-06], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(hessian, phi.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc26c6fb-e0ce-4246-8e4e-fba037a76023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6113e-05,  3.2472e-06,  1.0434e-05,  ..., -5.9264e-07,\n",
       "         4.9677e-07, -2.0703e-06], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.reshape(-1)*8e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f7ba0a8-351c-4e70-92bb-1cdb31ccb3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0012,  0.0051,  0.1549,  0.0139, -0.0057,  0.0166, -0.0391, -0.0140,\n",
       "          0.0126,  0.0058],\n",
       "        [ 0.0037, -0.0004, -0.0201, -0.0034, -0.0018,  0.0006, -0.0068, -0.0008,\n",
       "         -0.0059,  0.0016]], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi[:2,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ce78c5f7-5d95-4e8b-971f-406e52441808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0011, 0.0010, 0.0009, 0.0008, 0.0008, 0.0008, 0.0007],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b51d0-40a5-4440-8da1-9dc044affbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
